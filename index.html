<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="" />
  <meta property="og:description" content="" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Long-form Answers to Visual Questions from Blind and Low Vision People</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.35.2/gradio.js">
  </script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title publication-title">Long-form Answers to Visual Question from <br /> Blind and Low Vision
              People</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="http://www.minahuh.com" target="_blank">Mina Huh</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.cs.utexas.edu/~fxu/" target="_blank">Fangyuan Xu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.yihaopeng.tw/" target="_blank">Yi-Hao Peng</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://chongyanchen.com/" target="_blank">Chongyan Chen</a><sup>1</sup>,</span>
              <br />
              <span class="author-block">
                <a href="" target="_blank">Hansika Murugu</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://dannagurari.colorado.edu/" target="_blank">Danna Gurari</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="https://eunsol.github.io/" target="_blank">Eunsol Choi</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://www.amypavel.com" target="_blank">Amy Pavel</a><sup>1</sup>,</span>

            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">UT Austin<sup>1</sup>, CMU<sup>2</sup>, HKUST<sup>3</sup>, UC
                Boulder<sup>4</sup>, <br>COLM 2024</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2408.06303" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Arxiv</span>
                  </a>
                </span>

                <!-- Github link -->
<!--                 <span class="link-block">
                  <a href="/LFVQA/explorer.html" target="_blank" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fa fa-search"></i>
                    </span>
                    <span>Data Explorer</span>
                  </a>
                </span> -->
                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/UT-CS-HCI/lfvqa" target="_blank"
                    class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Data & Code</span>
                  </a>
                </span>
                <!-- Demo link -->
<!--                 <span class="link-block">
                  <a class="external-link button is-normal is-rounded ">
                    <span class="icon">
                      <i class="fa fa-image"></i>
                    </span>
                    <span>Demo</span>
                  </a>
                </span> -->




                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/2302.14117" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop is-centered has-text-centered">
      <div class="hero-body">
        <img src="static/images/teaser-lfvqa.jpg" style="margin-bottom: 2%;" alt="" width="85%" />
        <h2 class="subtitle has-text-centered">
          Our dataset <i>VizWiz-LF</i> contains 4.2k long-form answers to visual questions, collected from human expert describers and six VQA models.
          To understand the content and structure of long-form visual question answers (LFVQA),
          we create a taxonomy of functional roles and annotate answer functional roles and information types at a
          sentence level.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Vision language models can now generate long-form answers to questions
              about images â€“ <b>long-form visual question answers (LFVQA)</b>. We contribute
              <b>VizWiz-LF</b>, a dataset of long-form answers to visual questions posed by
              blind and low vision (BLV) users. VizWiz-LF contains 4.2k long-form answers to visual questions, collected
              from human expert describers and six
              VQA models. We develop and annotate functional roles of sentences in
              LFVQA and demonstrate that long-form answers contain information beyond the answer such as explanations
              and suggestions. We further evaluate
              360 long-form answers with BLV and sighted people to understand their
              preferences and assess the correctness of the long-form answers. Long-form
              answers generated by models often hallucinate with incorrect information
              to unanswerable questions (e.g., blurry images), yet BLV people often perceive these long-form answers as
              correct. To reduce hallucinations, we
              evaluate VQA models on their ability to correctly abstain from answering
              unanswerable questions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->



  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">VizWiz-LF Dataset</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <img src="static/images/dataset_overview.jpg" alt="" /><br>
            <h2 class="subtitle has-text-centered">
              To construct VizWiz-LF dataset, we first sample image-question pairs from the orginal VizWiz dataset.
              For each visual question, we collect an answer from human expert describers and six vision language models.
            </h2>
          </div>
        </div>
    <br><br><hr style="background-color: lightgray;"><br><br>
    <!-- <br><hr style="background-color: lightgray;"><br> -->
        <h2 class="title is-3">Short vs Long Answers</h2><br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <img src="static/images/qualitative_examples.png" alt="" /><br>
            <h2 class="subtitle has-text-centered">
            While traditional visual question answering (VQA) datasets contain short-form answers collected from crowdworkers,
            long-form visual question answering (LFVQA) has a lot of potential providing detailed and nuanced answers including explanations.
            When answers cannot be found from the provided image, long-form answers can still provide potential answers and suggestions to re-take the photos.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>

<br><hr style="background-color: lightgray;"><br>
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Functional Roles</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <img src="static/images/functional_roles.png" width="70%"
              alt="" /><br/><br/>
            <h3 class="subtitle">
              Definitions and examples of functional roles identified in our dataset
            </h3>
          </div>
        </div>
        <br><hr style="background-color: lightgray;"><br>
        <h2 class="title is-3">Information Types</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <img src="static/images/information_types.png" width="70%"
              alt="" /><br/><br/>
            <h3 class="subtitle">
              Definitions and examples of information types identified in our dataset
            </h3><br><br>
          </div>
        </div>
      </div>
    </div>
</section>

<!-- <br><hr style="background-color: lightgray;"><br> -->



    <!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Evaluation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="static/images/evaluation.jpg" width="70%" style="margin-right: 20%;"/>
          <h2 class="subtitle has-text-centered">
            After the video editing tasks, we measured the cognitive load using NASA-TLX. AVscript significantly outperformed usersâ€™ own video editing tools in mental demand, temporal demand, effort, and frustration.
            AVscript was also rated significantly better in the confidence in the output, independence in reviewing output, and
            helpfulness in identifying errors.
        </h2>
        </div>
      </div>
    </div>
  </div>
</section> -->

    <!-- Youtube video -->
    <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Presentation Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/YzCC3NcGVrM?start=1998&end=2910" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
    <!-- End youtube video -->




    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>Coming Soon...</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a>.
                <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>
